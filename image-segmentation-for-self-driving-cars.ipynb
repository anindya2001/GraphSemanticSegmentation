{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport os\nimport matplotlib.pyplot as plot\nfrom PIL import Image\nimport cv2\nfrom sklearn.cluster import KMeans\nimport random\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, Dense, Dropout, LeakyReLU, UpSampling2D, concatenate\nfrom keras.optimizers import Adam, SGD\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def LoadImage(name, path=\"../input/cityscapes_data/cityscapes_data/train\",\n             rotation=0.0, flip=False, cut_bottom=58,\n             size=(256, 200)):\n    img = Image.open(path+\"/\"+name)\n    img = np.array(img)\n    seg = img[:-cut_bottom, 256:]\n    img = img[:-cut_bottom, 0:256]\n    \n    for i in range(3):\n        zimg = img[:,:,i]\n        zimg = cv2.equalizeHist(zimg)\n        img[:,:,i] = zimg\n    \n    img = Image.fromarray(img).resize(size)\n    seg = Image.fromarray(seg).resize(size)\n    \n    \n\n    img = img.rotate(rotation)\n    seg = seg.rotate(rotation)\n\n    img = np.array(img)\n    seg = np.array(seg)\n\n    if flip:\n        img = img[:,::-1,:]\n        seg = seg[:,::-1,:]\n\n        #seg = np.round(seg/255.0)\n    \n    return img/255, seg/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files =os.listdir(\"../input/cityscapes_data/cityscapes_data/train\")[0:10]\n\ncolors = []\nfor file in files:\n    img, seg = LoadImage(file)\n    colors.append(seg.reshape(seg.shape[0]*seg.shape[1], 3))\ncolors = np.array(colors)\ncolors = colors.reshape((colors.shape[0]*colors.shape[1],3))\n\nkm = KMeans(13)\nkm.fit(colors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LayersToRGBImage(img):\n    colors = [(255,0,0), (0,255,0), (0,0,255),\n             (255,255,0), (255,0,255), (0,255,255),\n             (255,255,255), (200,50,0),(50,200,0),\n             (50,0,200), (200,200,50), (0,50,200),\n             (0,200,50), (0,0,0)]\n    \n    nimg = np.zeros((img.shape[0], img.shape[1], 3))\n    for i in range(img.shape[2]):\n        c = img[:,:,i]\n        col = colors[i]\n        \n        for j in range(3):\n            nimg[:,:,j]+=col[j]*c\n    nimg = nimg/255.0\n    return nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ColorsToClass(seg):\n    s = seg.reshape((seg.shape[0]*seg.shape[1],3))\n    s = km.predict(s)\n    s = s.reshape((seg.shape[0], seg.shape[1]))\n    \n    n = len(km.cluster_centers_)\n    \n    cls = np.zeros((seg.shape[0], seg.shape[1], n))\n    \n    for i in range(n):\n        m = np.copy(s)\n        m[m!=i] = 0\n        m[m!=0] = 1\n        \n        cls[:,:,i]=m\n        \n    return cls\n\nimg, seg = LoadImage(\"174.jpg\")\nseg2 = ColorsToClass(seg)\nseg2 = LayersToRGBImage(seg2)\ntotal = cv2.addWeighted(img, 0.6, seg2, 0.4, 0)\nplot.imshow(total[:,:,:])\nplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Generate(path=\"../input/cityscapes_data/cityscapes_data/train\", batch_size=20,\n            maxangle=10.0):\n    \n    files = os.listdir(path)\n    while True:\n        imgs=[]\n        segs=[]\n        \n        for i in range(batch_size):\n            file = random.sample(files,1)[0]\n            \n            flip=False\n            if random.random() > 0.5:\n                flip=True\n            \n            angle = maxangle*(random.random()*2-1)\n            \n            img, seg = LoadImage(file, path, rotation=angle, flip=flip)\n            \n            seg = ColorsToClass(seg)\n            \n            imgs.append(img)\n            segs.append(seg)\n        yield np.array(imgs), np.array(segs)\n        \ngen = Generate()\nimgs, segs = next(gen)\n\nplot.subplot(121)\nplot.imshow(imgs[0])\nplot.subplot(122)\nplot.imshow(LayersToRGBImage(segs[0]))\nplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inp = Input(shape=(200, 256, 3))\n\nx1 = BatchNormalization()(inp)\nx1 = Conv2D(64, 12, activation=\"relu\", padding=\"same\")(x1)\nx1 = Conv2D(128, 12, activation=\"relu\", padding=\"same\")(x1)\np1 = MaxPooling2D()(x1)\n#p1 = Dropout(0.2)(p1)\n\n#x2 = BatchNormalization()(x1)\nx2 = Conv2D(128, 9, activation=\"relu\", padding=\"same\")(p1)\nx2 = Conv2D(128, 9, activation=\"relu\", padding=\"same\")(x2)\np2 = MaxPooling2D()(x2)\n#p2 = Dropout(0.2)(p2)\n\n#x3 = BatchNormalization()(x2)\nx3 = Conv2D(128, 6, activation=\"relu\", padding=\"same\")(p2)\nx3 = Conv2D(128, 6, activation=\"relu\", padding=\"same\")(x3)\np3 = MaxPooling2D()(x3)\n#p3 = Dropout(0.2)(p3)\n\n#x4 = BatchNormalization()(x3)\nx4 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(p3)\nx4 = Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x4)\n#x4 = MaxPooling2D()(x4)\n#x4 = Dropout(0.2)(x4)\n\nx5 = UpSampling2D()(x4)\nx5 = concatenate([x3, x5])\nx5 = Conv2D(128, 6, activation=\"relu\", padding=\"same\")(x5)\nx5 = Conv2D(128, 6, activation=\"relu\", padding=\"same\")(x5)\n#x5 = Dropout(0.2)(x5)\n\nx6 = UpSampling2D()(x5)\nx6 = concatenate([x2, x6])\nx6 = Conv2D(128, 6, activation=\"relu\", padding=\"same\")(x6)\nx6 = Conv2D(128, 6, activation=\"relu\", padding=\"same\")(x6)\n#x6 = Dropout(0.2)(x6)\n\nx7 = UpSampling2D()(x6)\nx7 = concatenate([x1, x7])\nx7 = Conv2D(13, 6, activation=\"relu\", padding=\"same\")(x7)\nx7 = Conv2D(13, 6, activation=\"softmax\", padding=\"same\")(x7)\n\n\n\nmodel = Model(inp, x7)\n\nopt = Adam(lr=0.0001)\nmodel.compile(optimizer=opt,\n             loss=\"categorical_crossentropy\",\n             metrics=[\"accuracy\"])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = Generate()\nval_gen = Generate(\"../input/cityscapes_data/cityscapes_data/val\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clb = [ModelCheckpoint(\"loss.h5\", save_best_only=True, verbose=0)]\n\nh = model.fit_generator(train_gen, epochs=1000, steps_per_epoch=10,\n                       validation_data=val_gen, validation_steps=10,\n                       callbacks=clb, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model.h5\")\nmodel = load_model(\"loss.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = h.history[\"val_loss\"]\nacc = h.history[\"val_acc\"]\n\nplot.figure(figsize=(12, 6))\nplot.subplot(211)\nplot.title(\"Val. Loss\")\nplot.plot(loss)\nplot.xlabel(\"Epoch\")\nplot.ylabel(\"Loss\")\n\nplot.subplot(212)\nplot.title(\"Val. Accuracy\")\nplot.plot(acc)\nplot.xlabel(\"Epoch\")\nplot.ylabel(\"Accuracy\")\n\nplot.tight_layout()\nplot.savefig(\"learn.png\", dpi=150)\nplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen = Generate(\"../input/cityscapes_data/cityscapes_data/val\")\nmax_show=50\nfor imgs, segs in test_gen:\n    p = model.predict(imgs)\n    for i in range(p.shape[0]):\n        if i > max_show:\n            break\n        _p = LayersToRGBImage(p[i])\n        _s = LayersToRGBImage(segs[i])\n        \n        predimg = cv2.addWeighted(imgs[i], 0.6, _p, 0.4, 0)\n        trueimg = cv2.addWeighted(imgs[i], 0.6, _s, 0.4, 0)\n        plot.figure(figsize=(12,6))\n        plot.subplot(121)\n        plot.title(\"Prediction\")\n        plot.imshow(predimg)\n        plot.axis(\"off\")\n        plot.subplot(122)\n        plot.title(\"True\")\n        plot.imshow(trueimg)\n        plot.axis(\"off\")\n        plot.tight_layout()\n        plot.savefig(\"pred_\"+str(i)+\".png\", dpi=150)\n        plot.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, balanced_accuracy_score\ntest_gen = Generate(\"../input/cityscapes_data/cityscapes_data/val\", batch_size=200)\nmax_show=50\n\nbass = []\n\nfor imgs, segs in test_gen:\n    p = model.predict(imgs)\n    \n    plot.figure(figsize=(10, 10))\n    for i in range(p.shape[-1]):\n        fpr, tpr, _ = roc_curve(segs[:,:,:,i].ravel(), p[:,:,:,i].ravel())\n        \n        _p = np.round(p[:,:,:,i].ravel()).astype(np.int32)\n        bas = balanced_accuracy_score(segs[:,:,:,i].ravel(), _p)\n        \n        bass.append(bas)\n        \n        plot.subplot(4,4,i+1)\n        plot.plot(fpr, tpr)\n        plot.title(\"Class \"+str(i))\n        plot.xlabel(\"False positive rate\")\n        plot.ylabel(\"True positive rate\")\n    \n    plot.tight_layout()\n    plot.show()\n    \n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot.figure(figsize=(8, 5))\nplot.bar(np.arange(0, len(bass)), bass)\nplot.xticks(np.arange(0, len(bass)))\nplot.ylabel(\"Balanced Accuracy\")\nplot.xlabel(\"Class\")\nplot.tight_layout()\nplot.savefig(\"bas.png\")\nplot.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}